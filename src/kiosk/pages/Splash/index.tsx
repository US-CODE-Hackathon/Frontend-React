import * as C from '@/allFiles';
import * as S from './style';

import { motion, AnimatePresence } from 'framer-motion';
import { useRef, useState, useEffect, type JSX } from 'react';
import { MdKeyboardVoice } from 'react-icons/md';
import { MainImg } from '@/kiosk/assets';
import useMediaRecorder from './useMediaRecorder';
import { useNavigate } from 'react-router-dom';
import { TextToSpeech } from '@/kiosk/common/services/textToSpeech';
import { speechToText } from '@/kiosk/common/services/speechToText';
import { audioConverter } from '@/kiosk/common/utils/audioConverter';
import { getEmotionQuestion } from '@/kiosk/services/Splash/getEmotionQuestion';
import { getBiographyQuestion } from '@/kiosk/services/Splash/getBiographyQuestion';
import type { QuestionResponse } from '@/kiosk/services/Splash/getEmotionQuestion';
import { postQuestionAnswer } from '@/kiosk/services/Splash/postQuestionAnswer';
import { useLocation } from 'react-router-dom';

const KioskSplash: React.FC = () => {
  const { recording, recordedBlob, duration, startRecording, stopRecording, resetRecording } =
    useMediaRecorder();

  const [showModal, setShowModal] = useState<boolean>(false);
  const [finalTranscript, setFinalTranscript] = useState<string>('');
  const hasProcessedRef = useRef(false);
  const [liveTranscript, setLiveTranscript] = useState('');
  const [isSubmitting, setIsSubmitting] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const location = useLocation();
  const type = location.state?.type ?? 'EMOTION';
  const [questionData, setQuestionData] = useState<QuestionResponse | null>(null);
  const conversationId = 1;
  const [text, setText] = useState<'initial' | 'updated'>(() =>
    type === 'AUTOBIOGRAPHY' ? 'updated' : 'initial',
  );

  const navigate = useNavigate();

  useEffect(() => {
    setIsSubmitting(true);
    setError(null);

    const fetchQuestion = async () => {
      try {
        const data =
          type === 'AUTOBIOGRAPHY'
            ? await getBiographyQuestion(conversationId)
            : await getEmotionQuestion(conversationId);
        setQuestionData(data);
      } catch (err) {
        console.error('ì§ˆë¬¸ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨:', err);
        setError('ì§ˆë¬¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”.');
      } finally {
        setIsSubmitting(false);
      }
    };

    fetchQuestion();
  }, [conversationId]);

  useEffect(() => {
    const timer = setTimeout(() => {
      startRecording();
    }, 300);

    return () => {
      clearTimeout(timer); // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ í´ë¦°ì—…
    };
  }, []);

  useEffect(() => {
    if (text === 'initial') {
      TextToSpeech('ë°•í¬ì§„ ì–´ë¥´ì‹ , ë°˜ê°‘ìŠµë‹ˆë‹¤', () => {
        if (questionData?.question) {
          TextToSpeech(questionData.question);
        }
      });
    } else if (text === 'updated' && questionData) {
      TextToSpeech(questionData.question);
    }
  }, [text, questionData]);

  // ì´ˆê¸° í…ìŠ¤íŠ¸ ë³€ê²½ íƒ€ì´ë¨¸
  useEffect(() => {
    console.log('ì´ˆê¸° í…ìŠ¤íŠ¸ íƒ€ì´ë¨¸ ì„¤ì • | text:', text);
    const timer = setTimeout(() => {
      console.log('í…ìŠ¤íŠ¸ ìƒíƒœ ë³€ê²½: initial -> updated');
      setText('updated');
    }, 4000);

    return () => {
      console.log('cleanup: ì´ˆê¸° í…ìŠ¤íŠ¸ íƒ€ì´ë¨¸ ì œê±°');
      clearTimeout(timer);
    };
  }, []);

  // ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œì‘
  useEffect(() => {
    if (!('webkitSpeechRecognition' in window)) return;

    const recognition = new window.webkitSpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'ko-KR';

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      let transcript = '';
      for (let i = event.resultIndex; i < event.results.length; i++) {
        transcript += event.results[i][0].transcript;
      }
      setLiveTranscript(transcript);
    };

    if (recording) recognition.start();
    else recognition.stop();

    return () => recognition.stop();
  }, [recording]);

  // ìë™ ë…¹ìŒ ì‹œì‘
  useEffect(() => {
    if (!recording && recordedBlob && !showModal && !hasProcessedRef.current) {
      console.log('ğŸ“¦ ë…¹ìŒ ì™„ë£Œ â†’ ì„œë²„ë¡œ ì „ì†¡ ì¤€ë¹„');
      hasProcessedRef.current = true;

      audioConverter(recordedBlob)
        .then(resultText => {
          setFinalTranscript(liveTranscript);
          setShowModal(true);
        })
        .catch(err => {
          console.error('âŒ STT ì‹¤íŒ¨:', err);
          setFinalTranscript('ì¸ì‹ ì‹¤íŒ¨');
          setShowModal(true);
        });
    }
  }, [recording, recordedBlob, showModal]);

  const handleRetry = (): void => {
    setLiveTranscript('');
    console.log('handleRetry í˜¸ì¶œë¨ | ëª¨ë‹¬ ë‹«ê³  ë…¹ìŒ ì¬ì‹œì‘');
    setShowModal(false);
    hasProcessedRef.current = false;
    resetRecording();
    setFinalTranscript('');
    setTimeout(() => {
      console.log('0.3ì´ˆ í›„ ë…¹ìŒ ì¬ì‹œì‘');
      startRecording();
    }, 300);
  };

  const handleConfirm = (): void => {
    if (!recordedBlob || !questionData) return;

    setShowModal(false);
    setLiveTranscript('');
    setFinalTranscript(''); // ê¸°ì¡´ í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
    setIsSubmitting(true); // âœ… ì „ì†¡ì¤‘ ìƒíƒœ true

    audioConverter(recordedBlob)
      .then(wavBlob => {
        const wavFile = new File([wavBlob], 'voice.wav', { type: 'audio/wav' });
        return speechToText(wavFile); // /stt ì „ì†¡
      })
      .then(resultText => {
        setFinalTranscript(resultText);
        const payload = {
          conversationId: questionData.conversationId,
          questionId: questionData.questionId,
          type: questionData.type,
          question: questionData.question,
          content: resultText, // â¬…ï¸ resultTextë¡œ ë°”ê¿”ì£¼ì„¸ìš”
        };

        console.log('ğŸ“¦ ë‹µë³€ ì „ì†¡ ì¤€ë¹„:', payload);

        return postQuestionAnswer(payload).then(() => resultText); // âœ… resultText ë„˜ê²¨ì¤Œ
      })
      .then(resultText => {
        // âœ… ì „ì†¡ ëë‚˜ê³  í˜ì´ì§€ ì´ë™
        setIsSubmitting(false);
        navigate('/ongoing', { state: { userResponse: resultText } });
      })
      .catch(err => {
        console.error('âŒ ì „ì†¡ ì‹¤íŒ¨:', err);
        setFinalTranscript('ì „ì†¡ ì‹¤íŒ¨');
        setIsSubmitting(false); // ì‹¤íŒ¨ ì‹œ ë‹¤ì‹œ false
      })
      .finally(() => {
        setIsSubmitting(false);
      });
  };

  const formatDuration = (duration: number): string => {
    const minutes = Math.floor(duration / 60);
    const seconds = duration % 60;
    return `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
  };

  const renderVoiceUI = () => (
    <>
      <S.VoiceWrapper>
        {recording && (
          <S.GuideText>
            ğŸ‘‡ ì´ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ <strong>ë…¹ìŒì´ ëë‚˜ìš”!</strong>
          </S.GuideText>
        )}
        <button
          onClick={() => {
            console.log('ğŸ™ ë²„íŠ¼ í´ë¦­ â†’ ë…¹ìŒ ì¢…ë£Œ ì‹œë„');
            stopRecording();
          }}
          disabled={!recording}
        >
          <MdKeyboardVoice />
        </button>
      </S.VoiceWrapper>
      {recording && (
        <S.RecordWrapper>
          ëª©ì†Œë¦¬ê°€ ë…¹ìŒë˜ê³  ìˆì–´ìš”
          <br />
          {recording && (
            <div
              style={{
                marginTop: '10px',
                fontSize: '0.9em',
                color: '#333',
                background: '#f0f0f0',
                padding: '8px',
                borderRadius: '8px',
                maxWidth: '300px',
                wordBreak: 'keep-all',
              }}
            >
              ì‹¤ì‹œê°„: "{liveTranscript}"
            </div>
          )}
        </S.RecordWrapper>
      )}
      {showModal && (
        <S.ModalOverlay>
          <S.ModalContent>
            <h2>ë§ì”€í•˜ì‹  ë‚´ìš©ì´ ë§ë‚˜ìš”?</h2>
            <h3>ì¸ì‹ëœ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”</h3>
            <div className="transcript">{finalTranscript || 'ì¸ì‹ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.'}</div>
            <S.BtnGroup>
              <C.KioskButton onClick={handleConfirm}>ë§ì•„ìš”</C.KioskButton>
              <motion.button
                onClick={handleRetry}
                className="replay"
                whileHover={{ scale: 1.05 }}
                whileTap={{ scale: 0.95 }}
                transition={{ duration: 0.2, ease: 'easeInOut' }}
              >
                ë‹¤ì‹œ ë§í•˜ê¸°
              </motion.button>
            </S.BtnGroup>
            <p>
              ğŸ’¡ ë‚´ìš©ì´ í‹€ë ¸ë‹¤ë©´ <span>"ë‹¤ì‹œ ë§í•˜ê¸°"</span>ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”
            </p>
          </S.ModalContent>
        </S.ModalOverlay>
      )}
    </>
  );

  const renderTextContent = (): JSX.Element => {
    if (type === 'AUTOBIOGRAPHY' && questionData) {
      return (
        <>
          <span>í¬ì§„ í• ë¨¸ë‹ˆ,</span> <br />
          {questionData.question}
          {renderVoiceUI()}
        </>
      );
    }

    if (text === 'initial') {
      return (
        <>
          <span>ë°•í¬ì§„ ì–´ë¥´ì‹ , ë°˜ê°‘ìŠµë‹ˆë‹¤ </span>
        </>
      );
    }

    if (error) {
      return (
        <div style={{ color: 'red', fontWeight: 'bold' }}>
          âš ï¸ {error}
          <br />
          <button
            onClick={() => window.location.reload()}
            style={{
              marginTop: '8px',
              padding: '6px 12px',
              border: '1px solid #ccc',
              background: '#fff',
              borderRadius: '4px',
            }}
          >
            ë‹¤ì‹œ ì‹œë„í•˜ê¸°
          </button>
        </div>
      );
    }

    if (!questionData) {
      return <div>ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.</div>;
    }

    return (
      <>
        <span>í¬ì§„ í• ë¨¸ë‹ˆ,</span> <br />
        {questionData.question}
        {renderVoiceUI()}
      </>
    );
  };

  return (
    <S.SplashContainer>
      <S.SplashWrapper>
        <C.KioskHeader />
        <S.SplashImgWrapper>
          <motion.img
            src={MainImg}
            alt="ë©”ì¸ ì´ë¯¸ì§€"
            initial={{ y: 100, scale: 1, opacity: 1 }}
            animate={{ y: 0, scale: 0.8, opacity: 1 }}
            exit={{ y: -100, scale: 0.8, opacity: 0 }} // ìˆ˜ì •ëœ ë¶€ë¶„
            transition={{ duration: 0.5, ease: 'easeInOut' }}
          />
          <motion.div
            initial={{ y: 100, opacity: 0 }}
            animate={{ y: 0, opacity: 1 }}
            exit={{ y: -100, opacity: 0 }}
            transition={{ duration: 0.5, ease: 'easeInOut', delay: 0.2 }}
          >
            <AnimatePresence mode="wait">
              {isSubmitting ? (
                <motion.h1
                  key="submitting"
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ opacity: 1, y: 0 }}
                  exit={{ opacity: 0, y: -20 }}
                  transition={{ duration: 0.3, ease: 'easeInOut' }}
                >
                  ë‹µë³€ì„ ì „ì†¡í•˜ê³  ìˆì–´ìš” â˜ºï¸
                </motion.h1>
              ) : (
                <motion.h1
                  key={text}
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ opacity: 1, y: 0 }}
                  exit={{ opacity: 0, y: -20 }}
                  transition={{ duration: 0.3, ease: 'easeInOut' }}
                >
                  {renderTextContent()}
                </motion.h1>
              )}
            </AnimatePresence>
          </motion.div>
        </S.SplashImgWrapper>
      </S.SplashWrapper>
    </S.SplashContainer>
  );
};

export default KioskSplash;
